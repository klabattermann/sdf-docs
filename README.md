**Lustre Filesystem Storage Issue**

**UPDATE Saturday February 24th 7:30PM PST: The Lustre filesystem is still online with 8 remaining drive rebuilds. DDN advised us to rebuild one drive at a time. Each rebuild takes around 40 hours.** 



Welcome to the SLAC Shared Scientific Data Facility (S3DF). The S3DF
is a compute, storage and network architecture designed to support
massive scale analytics required by all SLAC experimental facilities
and programs, including LCLS/LCLS-II, UED, cryo-EM, the accelerator,
and the Rubin observatory. The S3DF infrastructure is optimized for
data analytics and is characterized by large, massive throughput, high
concurrency storage systems.

## Quick Reference

| Access 	| Address | 
| :--- | :--- |
| SSH 	|  s3dflogin.slac.stanford.edu|
| NoMachine |  s3dfnx.slac.stanford.edu|
| OnDemand 	| [https://s3df.slac.stanford.edu/ondemand](/ondemand ':ignore') |	
| Globus Endpoint 	| slac_globus5_test|
| Documentation | [This!](/ ':ignore')|
| Help (slack channel) | [slac.slack.com#comp-sdf](https://app.slack.com/client/T1X4J8FJ8/C01965DTG91)|
| Help (email) | s3df-help@slac.stanford.edu|
| Banking & Accounting | https://s3df.slac.stanford.edu/coact|
| S3DF Dashboard & Monitoring | https://grafana.slac.stanford.edu|


![SRCF-II](assets/srcf-ii.png)
